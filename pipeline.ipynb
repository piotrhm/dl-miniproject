{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biw2wtIGuxoO"
   },
   "source": [
    "# ViT vs CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BXqPNcOYA0-h",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import io\n",
    "import glob\n",
    "\n",
    "import BiT\n",
    "from ViT import modeling as ViT\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as Img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xTIMaZBOuxoU"
   },
   "outputs": [],
   "source": [
    "dataset_path = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T0ohcnnTgsdU"
   },
   "outputs": [],
   "source": [
    "def get_weights(path):\n",
    "  return np.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m61ZHyIUuxoV"
   },
   "source": [
    "## Prepare dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (384, 384)\n",
    "NORMALIZE_MEAN = (0.5, 0.5, 0.5)\n",
    "NORMALIZE_STD = (0.5, 0.5, 0.5)\n",
    "transforms = [\n",
    "              T.Resize(IMG_SIZE),\n",
    "              T.ToTensor(),\n",
    "              T.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "              ]\n",
    "\n",
    "transforms = T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ylaiH85zuxoW"
   },
   "outputs": [],
   "source": [
    "def load_images(dataset_path: str) -> List[Img]:\n",
    "    images = []\n",
    "    for filename in glob.glob(dataset_path + '/*'):\n",
    "        im=Image.open(filename).convert('RGB')\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_vit(model_name='ViT-H_14') -> nn.Module:\n",
    "    config = ViT.CONFIGS[model_name]\n",
    "    model = ViT.VisionTransformer(config, img_size=384, vis=True)\n",
    "    model.load_from(get_weights('imagenet21k-' + model_name + '.npz'))\n",
    "    return model\n",
    "    \n",
    "def load_bit(model_name='BiT-M-R152x4') -> nn.Module:\n",
    "    model = BiT.KNOWN_MODELS[model_name]()\n",
    "    model.load_from(get_weights(model_name + '.npz'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9oHO_8vSuxoW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_pretrained: grid-size from 16 to 27\n"
     ]
    }
   ],
   "source": [
    "images = load_images(dataset_path)\n",
    "vit = load_vit()\n",
    "bit = load_bit()\n",
    "\n",
    "img = images[0]\n",
    "img_tensor = transforms(img).unsqueeze(0)\n",
    "out_vit = vit(img_tensor)\n",
    "out_bit = bit(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wxf-JQ6uxoW"
   },
   "source": [
    "## Compare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ixCuHDCSuxoW"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\u001b[93mFailed test!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-69511d097ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\033[93m'\u001b[0m \u001b[0;34m'Failed test!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[92m'\u001b[0m \u001b[0;34m'Passed test!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \u001b[93mFailed test!"
     ]
    }
   ],
   "source": [
    "assert np.allclose(out_vit[0].detach().numpy(), out_bit.detach().numpy()), '\\033[93m' 'Failed test!'\n",
    "\n",
    "print('\\033[92m' 'Passed test!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaoxjYYQuxoW"
   },
   "source": [
    "## Compare activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWcdGXoCuxoX"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvYo8vuiuxoX"
   },
   "source": [
    "## Compare embeddings clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdcOhBGxuxoX"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
